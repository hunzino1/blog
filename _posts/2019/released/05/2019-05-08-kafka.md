---
layout:     post
title:      kafka教程1 - kafka概述
category: stack
tags: [stack]
excerpt: 一个人有多努力，就会有多幸运。
---

kafka概述
=======================================

本篇博文主要是对kafka概念以及应用进行介绍，通过本篇博文你将了解到：

* kafka的结构
* 发布-订阅的实现
* kafka进阶

代码demo：[github](https://github.com/hunzino1/kafkaDemo)

-------------------------------------

1 kafka概述
---------------------------------

### 1.1 kafka的概念和用途

简单来说，kafka就是一个中间件，两个服务A/B之间用于传输数据的工具。

那么可以理解为kafka就是一个消息系统，就像服务之间传递数据的一个管道。

#### 对比消息队列 和 kafka

消息系统负责将数据从一个应用程序传输到另一个应用程序，因此业务服务可以专注于数据，不必担心如何共享数据。

两种消息系统模式

- 点对点
- 发布-订阅(pub-sub)消息系统， 大多数消息模式遵循 pub-sub 。

1 消息队列（点对点消息系统）：

点对点，即消息队列中的一条数据只能消费一次(出队操作)，一旦消费者读取队列中的消息，它就从该队列中消失。

所以，消息队列是一个可以多服务写入，多服务消费，实时的消息结构实现。

![message_queue](https://hunzino1.github.io/assets/images/2019/kafka/message_queue.jpg)

2 pub-sub消息系统

如图，在发布-订阅系统中，消息生产者称为发布者，消息使用者称为订阅者, 消息系统是一个中间件。

![publish_subscribe_messaging_system](https://hunzino1.github.io/assets/images/2019/kafka/publish_subscribe_messaging_system.jpg)

综上，kafka较之消息队列，实现一条数据供多个消费者消费，并可既可以实时消费又允许延迟消费，分布式数据支持高吞吐。

### 1.2 kafka结构以及组件术语

![kafka_struct](https://hunzino1.github.io/assets/images/2019/kafka/kafka_struct.jpg)

如图，kafka的四个主要组成部分是producer、consumer、topic、broker；

| 主要结构    | 说明                                   |
| --------    | :-----:                                 |
| producer    | kafka数据(消息)提供生产方              |
| consumer    | 消费kafka数据(消息)                    |
| topic       | 消息类别，一个topic是一组消息          |
| broker      | kafka 集群中包含的每一台服务器         |

#### 1.2.1 kafka消息传递流程

如上图，简言之，producer、consumer有多个，producer向多个topic中推送数据(push模式)，consumer消费topic中数据(pull模式)。

pub-sub模式，consumer订阅了topic，说明使用了观察者模式，主动pull消息。

问题：

consumer消费完topic一条消息后，消息会删吗？

猜测：不会，kafka就指定每一条message的过期时间，到期删除；而消费之后，该consumer只会记录自己在该topic消费的最新的offset，不必删除消息。

#### 1.2.2 其他术语定义

| kafka角色      | 说明                                   |
| --------       | :-----:                                 |
| consumer group | 每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 的一个 Consumer 消费，但可以被多个 consumer group 消费。   |
| partition      | topic的物理存储分配单元， 每个topic包含一个或多个partition。  |
| replica        | partition 的副本，保障 partition 的高可用。                   |
| leader         | replica 中的一个角色， producer 和 consumer 只跟 leader 交互  |
| follower       | replica 中的一个角色，从 leader 中复制数据。                  |
| controller     | kafka 集群中的其中一个服务器，用来进行 leader election(选举) 以及各种failover(容错/故障分析)。     |
| zookeeper      | kafka 通过 zookeeper 来存储集群的 meta 信息。meta(元语言、元数据)     |

```html
1、元数据：
  kafka中消息就是一个字节数组，对kafka而言他就是一个字节数据，而不考虑消息内容或者其意义，
         也就是每一条消息对于kafka而言没有特别的含义或者格式，只是一组字节而已。

2、broker：

broker是kafka集群中包含的一台服务器。

1) broker生产者服务：broker接收生产者的消息，为消息设置偏移量，将消息存入磁盘中（partition）。
   理解：offset、partition都是物理存储记录，即broker物理机器上的磁盘的位置标记；

2) broker消费者服务：broker接收消费者请求，broker响应读取请求，返回磁盘上的消息。

3、controller:

每个broker集群都有一个broker同时充当了controller的角色，
  即既是broker又是controller，是自动从集群的活跃成员中选举出来的。

controller负责管理工作，包括将partition分配给broker以及监控broker；
  分区复制提高容错，如果leader挂了，其他broker会接管leader。

4、kafka保留消息

kafka保留消息有两种类型： 保留一段时间 和 保留消息达到一定的大小。
每个topic可以设置自己的保留设置。
如果两个同时指定，满足其中一个就会删除。

```

#### 1.2.3 kafka详细流程

为了形象，按照生产消费的逻辑顺序，结合上图producer1、topic1说明：

1. producer1 将主题为topic1的一组message发布到kafka集群上，kafka汲取将消息数据分为part1、part2两部分；
2. 如图，part1、part2都保存了三份，随机存放到三个partition下；
3. controller对part1、part2数据所在的partition进行leader选举；
4. kafka上新增消息，定义topic1的consumer group1/2收到新增通知；
5. consumer group1/2 中个选出一个消费者对part1、part2所在的leader partition进行消费；consumer group 消费offset标记进行更新；

上述过程顺序不一定准确，只是为了对整体的消息数据流动以及数据状态变化作一介绍。

**几点总结**

1. kafka是按批次(一组消息)写入的，并且批次数据会被压缩； 目的是为了减少数据传递的网络开销；
2. Kafka 有四个核心的 API。客户端和服务器端的通信，是基于TCP 协议；
3. 一个topic有多个partition(不是leader和follower,是多个leader partition), producer均衡写入,consumer消费时是均衡选取，所以partition之间数据消费是无序的
4. 消费一个partition中的数据是有序的(队列)，不过可以通过调整offset的值消费特定数据；
5. consumer会把每个partition最后读取的消息偏移量保存在zookeeper或者kafka上，如果consumer关闭或重启，其读取状态也不会丢失；
6. kafka使用zookeeper保存集群的元数据和消费者信息。（见图）
7. 磁盘性能影响producer，内存影响consumer；因为consumer会将读取的消息放到系统的页面缓存中。
7. 顺序消费的实现如下：

```html
对于每一条消息数据，kafka提供了一个可选项，键, 对，就是hash结构k-v；其中，键也是元数据(字节数组)
此外，kafka存在一个分区器组件，用来确定消息分区；

如果一条消息存在键，那么分区器会计算键的散列值，并将其映射到指定partition；
这样，同样的key就会使得所有message写入到同一个partition中，从而实现顺序消费。

如果没有键存在，那么就均衡写入，均衡消费。
```

![kafka_zookeeper](https://hunzino1.github.io/assets/images/2019/kafka/kafka_zookeeper.png)

![kafka_zookeeper2](https://hunzino1.github.io/assets/images/2019/kafka/kafka_zookeeper2.png)

kafka 在 zookeeper 中的存储结构如下图所示：

![zk_content](https://hunzino1.github.io/assets/images/2019/kafka/zk_content.jpeg)

### 1.3 kafka多集群

为什么使用多集群？

对着kafka部署数量的增加，可能要考虑以下因素

- 数据类型分离
- 安全需求隔离
- 多数据中心(容灾恢复)

所以，需要实现多集群。

2 集群之间的数据同步

kafka MirrorMaker工具，原理MirrorMaker的核心组件是一个生产者和一个消费者，用来同步集群间的消息。

2 kafka API
------------------------------

ruby API

### 1 producer

如图，key可选

![producer](https://hunzino1.github.io/assets/images/2019/kafka/producer.png)

### 2 consumer

略


3 kafka性能调优
------------------------

### 1 虚拟内存

对于高吞吐量的应用，要尽量避免内存交换，因为内存页和磁盘之间的交换会对kafka的性能有很大影响。

```html
内存交换： 

内存交换（对换）的基本思想是，把处于等待状态（或在CPU调度原则下被剥夺运行权利） 的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。

打个比方：你的内存（主仓库）放满了，就临时把内存（主仓库）暂时不用的东西放到硬盘里（副仓库），这样内存（主仓库）可以放新的东西。如果要用旧的东西再从硬盘里（副仓库）搬回来。

有关交换需要注意以下几个问题：
　　1、交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。
　　2、为了有效使用CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。转移时间与所交换的内存空间成正比。
　　3、如果换出进程，必须确保该进程是完全处于空闲状态。
　　4、交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
　　5、交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
　　6、普通的交换使用不多，但交换策略的某些变种在许多系统中（如UNIX系统）仍发挥作用。
```

优化方案：

- 尽量避免内存交换， vm.swappiness参数值尽量小（1，新版本Red Hat内核0是任何情况下都不交换）

  内存交换有容错的作用，比如内存不足进程会中断，所以完全拒绝内存交换。

- 优化脏页和磁盘数据同步，vm.dirty_background_ratio(脏页占系统内存百分比，5，达到5刷新) 和 vm.dirty_ration参数（60~80）

```html
脏页：

因为硬盘的读写速度远赶不上内存的速度，系统就把读写比较频繁的数据事先放到内存中，以提高读写速度，这就叫高速缓存。
linux是以页作为高速缓存的单位，当进程修改了高速缓存里的数据时，该页就被内核标记为脏页。

内核将会在合适的时间把脏页的数据写到磁盘中去，以保持高速缓存中的数据和磁盘中的数据是一致的。
```

### 2 磁盘

1 磁盘选择（忽略）

2 一般日志片段存储在磁盘， 包括3个时间戳：创建时间(ctime) 最后修改时间(mtime) 最后访问时间(atime)

最后访问时间用处不大，可以忽略更新

### 2 网络

1 调整socket读写缓冲区的大小

2 调整TCP socket缓冲区的大小
