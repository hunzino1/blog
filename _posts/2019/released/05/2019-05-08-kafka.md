---
layout:     post
title:      kafka教程1 - kafka概述
category: stack
tags: [stack]
excerpt: 一个人有多努力，就会有多幸运。
---

kafka概述
=======================================

本篇博文主要是对kafka概念以及应用进行介绍，通过本篇博文你将了解到：

* kafka的结构
* 发布-订阅的实现
* kafka进阶

代码demo：[github](https://github.com/hunzino1/kafkaDemo)

-------------------------------------

1 kafka概述
---------------------------------

### 1.1 kafka的概念和用途

简单来说，kafka就是一个中间件，两个服务A/B之间用于传输数据的工具。

那么可以理解为kafka就是一个消息系统，就像服务之间传递数据的一个管道。

#### 对比消息队列 和 kafka

消息系统负责将数据从一个应用程序传输到另一个应用程序，因此业务服务可以专注于数据，不必担心如何共享数据。

两种消息系统模式

- 点对点
- 发布-订阅(pub-sub)消息系统， 大多数消息模式遵循 pub-sub 。

1 消息队列（点对点消息系统）：

点对点，即消息队列中的一条数据只能消费一次(出队操作)，一旦消费者读取队列中的消息，它就从该队列中消失。

所以，消息队列是一个可以多服务写入，多服务消费，实时的消息结构实现。

![message_queue](message_queue.jpg)

2 pub-sub消息系统

如图，在发布-订阅系统中，消息生产者称为发布者，消息使用者称为订阅者, 消息系统是一个中间件。

![publish_subscribe_messaging_system](publish_subscribe_messaging_system.jpg)

综上，kafka较之消息队列，实现一条数据供多个消费者消费，并可既可以实时消费又允许延迟消费，分布式数据支持高吞吐。

### 1.2 kafka结构以及组件术语

![kafka_struct](kafka_struct.jpg)

如图，kafka的四个主要组成部分是producer、consumer、topic、broker；

| 主要结构    | 说明                                   |
| --------    | -----:                                 |
| producer    | kafka数据(消息)提供生产方              |
| consumer    | 消费kafka数据(消息)                    |
| topic       | 消息类别，一个topic是一组消息          |
| broker      | kafka 集群中包含的每一台服务器         |

#### 1.2.1 kafka消息传递流程

如上图，简言之，producer、consumer有多个，producer向多个topic中推送数据(push模式)，consumer消费topic中数据(pull模式)。

pub-sub模式，consumer订阅了topic，说明使用了观察者模式，主动pull消息。

问题：

consumer消费完topic一条消息后，消息会删吗？

猜测：不会，kafka就指定每一条message的过期时间，到期删除；而消费之后，该consumer只会记录自己在该topic消费的最新的offset，不必删除消息。

#### 1.2.2 其他术语定义

| kafka角色      | 说明                                   |
| --------       | -----:                                 |
| consumer group | 每个 consumer 都属于一个 consumer group，每条消息只能被 consumer group 的一个 Consumer 消费，但可以被多个 consumer group 消费。   |
| partition      | topic的物理存储分配单元， 每个topic包含一个或多个partition。  |
| replica        | partition 的副本，保障 partition 的高可用。                   |
| leader         | replica 中的一个角色， producer 和 consumer 只跟 leader 交互  |
| follower       | replica 中的一个角色，从 leader 中复制数据。                  |
| controller     | kafka 集群中的其中一个服务器，用来进行 leader election(选举) 以及各种failover(容错/故障分析)。     |
| zookeeper      | kafka 通过 zookeeper 来存储集群的 meta 信息。meta(元语言、元数据)     |

```html
元数据： kafka中消息就是一个字节数组，对kafka而言他就是一个字节数据，而不考虑消息内容或者其意义，
         也就是每一条消息对于kafka而言没有特别的含义或者格式，只是一组字节而已。
```

#### 1.2.3 kafka详细流程

为了形象，按照生产消费的逻辑顺序，结合上图producer1、topic1说明：

1. producer1 将主题为topic1的一组message发布到kafka集群上，kafka汲取将消息数据分为part1、part2两部分；
2. 如图，part1、part2都保存了三份，随机存放到三个partition下；
3. controller对part1、part2数据所在的partition进行leader选举；
4. kafka上新增消息，定义topic1的consumer group1/2收到新增通知；
5. consumer group1/2 中个选出一个消费者对part1、part2所在的leader partition进行消费；consumer group 消费offset标记进行更新；

上述过程顺序不一定准确，只是为了对整体的消息数据流动以及数据状态变化作一介绍。

**几点总结**

1. kafka是按批次(一组消息)写入的，并且批次数据会被压缩； 目的是为了减少数据传递的网络开销；
2. Kafka 有四个核心的 API。客户端和服务器端的通信，是基于TCP 协议；
3. 一个topic有多个partition(不是leader和follower,是多个leader partition), consumer消费时是均衡选取，所以partition之间数据消费是无序的
4. 消费一个partition中的数据是有序的(队列)，不过可以通过调整offset的值消费特定数据；
5. 顺序消费的实现

```html
对于每一条消息数据，kafka提供了一个可选项，键, 对，就是hash结构k-v；其中，键也是元数据(字节数组)
此外，kafka存在一个分区器组件，用来确定消息分区；

如果一条消息存在键，那么分区器会计算键的散列值，并将其映射到指定partition；

这样，同样的key就会使得所有message写入到同一个partition中，从而实现顺序消费。

如果没有键存在，那么就均衡写入，均衡消费。
```
